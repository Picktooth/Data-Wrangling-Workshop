{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87dc5d5f",
   "metadata": {},
   "source": [
    "# NumPy Basics: Stats, Normalization, and Smoothing\n",
    "\n",
    "**Goal:** use NumPy arrays to implement the math-y parts of wrangling.\n",
    "\n",
    "**Covered:**\n",
    "- Computing descriptive stats and handle NaNs\n",
    "- Normalize/standardize arrays\n",
    "- Apply simple smoothing for noisy signals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a363c8",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "- Import `numpy as np`.\n",
    "- Assume we start from either a Pandas column (`df['col'].to_numpy()`) or a raw array `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad5ce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fdfc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------\n",
    "# GENERATING ARRAYS\n",
    "# ------------------\n",
    "\n",
    "rng = np.random.default_rng(7)\n",
    "\n",
    "# Section 2: stats with NaNs\n",
    "arr_nan = np.array([42.0, 50.0, np.nan, 60.0, 70.0, np.nan, 55.0])\n",
    "\n",
    "# Section 3: clean numeric with one outlier\n",
    "arr_clean = np.array([1., 5., 10., 12., 14., 15., 20., 22., 25., 200.])  # 200 is an outlier\n",
    "\n",
    "# Section 4: noisy signal for smoothing\n",
    "linspace = np.linspace(0, 2*np.pi, 40)\n",
    "signal_noisy = np.sin(linspace) + rng.normal(0, 0.15, size=linspace.size)\n",
    "signal_noisy[10] = np.nan  # one missing sample to show handling\n",
    "print(\"Demo arrays ready: arr_nan, arr_clean, signal_noisy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82acc65",
   "metadata": {},
   "source": [
    "## 2. Descriptive Stats with NaNs\n",
    "---\n",
    "**Dataset:** use `arr_nan` (a tiny 1D array).\n",
    "\n",
    "**Use:** `np.nanmean`, `np.nanmedian`, `np.nanstd` for arrays containing NaNs.\n",
    "- Plain `np.mean/median/std` will return `nan` if any NaN is present.\n",
    "- The `nan*` versions compute while **ignoring** NaNs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b48887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Section 2: Descriptive stats that ignore NaNs ---\n",
    "print(\"[nan-aware stats on arr_nan]\")\n",
    "print(f\"arr_nan: {arr_nan}\\n\")\n",
    "\n",
    "print(f\"np.mean      -> {np.mean(arr_nan)}\")         # returns nan\n",
    "print(f\"np.nanmean   -> {np.nanmean(arr_nan)}\\n\")    # ignores NaN\n",
    "\n",
    "print(f\"np.median    -> {np.median(arr_nan)}\")       # returns nan\n",
    "print(f\"np.nanmedian -> {np.nanmedian(arr_nan)}\\n\")  # ignores NaN\n",
    "\n",
    "print(f\"np.std       -> {np.std(arr_nan)}\")          # returns nan\n",
    "print(f\"np.nanstd    -> {np.nanstd(arr_nan)}\")       # ignores NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de75b954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------\n",
    "# Handling NaNs: count \n",
    "# Fill with constants/mean, \n",
    "# Forward-fill \n",
    "# Interpolation\n",
    "# --------------\n",
    "\n",
    "# Count NaNs\n",
    "nan_count = np.isnan(arr_nan).sum()\n",
    "print(f\"arr_nan: {arr_nan}\")\n",
    "print(f\"NaN count: {nan_count}\\n\")\n",
    "\n",
    "# Fill with 0\n",
    "filled_zero = np.nan_to_num(arr_nan, nan=0.0)\n",
    "print(\"[Fill NaNs with 0]\")\n",
    "print(filled_zero, \"\\n\")\n",
    "\n",
    "# Fill with mean\n",
    "mu = np.nanmean(arr_nan)\n",
    "filled_mean = np.nan_to_num(arr_nan, nan=mu)\n",
    "print(f\"[Fill NaNs with mean={mu:.2f}]\")\n",
    "print(filled_mean, \"\\n\")\n",
    "\n",
    "# Interpolation across gaps (linear)\n",
    "arr_interp = arr_nan.copy()\n",
    "mask = np.isnan(arr_interp)\n",
    "if mask.any():\n",
    "    idx = np.arange(arr_interp.size)\n",
    "    arr_interp[mask] = np.interp(idx[mask], idx[~mask], arr_interp[~mask])\n",
    "print(\"[Linear interpolation across NaNs]\")\n",
    "print(arr_interp, \"\\n\")\n",
    "\n",
    "# True forward-fill (carry last valid value)\n",
    "arr_ffill = arr_nan.copy()\n",
    "mask = np.isnan(arr_ffill)\n",
    "idx = np.where(~mask, np.arange(arr_ffill.size), 0)\n",
    "np.maximum.accumulate(idx, out=idx)\n",
    "arr_ffill = arr_ffill[idx]\n",
    "print(\"[Forward-fill NaNs (carry last valid)]\")\n",
    "print(arr_ffill)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdc4938",
   "metadata": {},
   "source": [
    "## 3. Normalization & Standardization\n",
    "---\n",
    "**Dataset:** use `arr_clean` (1D array with an outlier).\n",
    "> How do outliers influence our normalization & standardization methods?\n",
    "\n",
    "**Formulas (NumPy algebra):**\n",
    "- Min–max: `(x - x.min()) / (x.max() - x.min())`\n",
    "- Z-score: `(x - x.mean()) / x.std()`\n",
    "- Robust (median/Median Absolute Deviation): `(x - median) / MAD` where `MAD = median(|x - median|)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de071e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------\n",
    "# Normalization/Standardization\n",
    "# --------------\n",
    "\n",
    "x = arr_clean.copy()\n",
    "print(\"Original:\", x)\n",
    "print('-' * 50)\n",
    "\n",
    "# Min–max\n",
    "x_min, x_max = x.min(), x.max()\n",
    "x_minmax = (x - x_min) / (x_max - x_min)\n",
    "print(\"[Min–max scaling]\")\n",
    "print(x_minmax)\n",
    "print('-' * 50)\n",
    "\n",
    "# Z-score\n",
    "mu, sigma = x.mean(), x.std()\n",
    "x_z = (x - mu) / sigma\n",
    "print(\"[Z-score standardization]\")\n",
    "print(x_z)\n",
    "print('-' * 50)\n",
    "\n",
    "# Robust scaling (median/MAD)\n",
    "med = np.median(x)\n",
    "mad = np.median(np.abs(x - med))\n",
    "x_robust = (x - med) / mad\n",
    "print(\"[Robust scaling: median/MAD]\")\n",
    "print(x_robust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8288f8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot unsclaed vs scaled arrays\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(x, 'o-', label='Original', markersize=8)\n",
    "plt.plot(x_minmax, 'o-', label='Min–max', markersize=8)\n",
    "plt.plot(x_z, 'o-', label='Z-score', markersize=8)\n",
    "plt.plot(x_robust, 'o-', label='Robust (med/MAD)', markersize=8)\n",
    "plt.title('Normalization/Standardization Methods')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4d554b",
   "metadata": {},
   "source": [
    "## 4. Smoothing / Noise Reduction\n",
    "---\n",
    "**Dataset:** use `signal_noisy` (noisy sine wave) to show the effect without plots.\n",
    "\n",
    "- Simple moving average (SMA) with window `k` using 1D convolution\n",
    "- Exponential moving average (EMA) with decay `alpha`\n",
    "- Handle NaNs first so filters don't propagate missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd62204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------\n",
    "# Smoothing a noisy 1D signal\n",
    "# --------------\n",
    "\n",
    "# Implementation for simple moving average assisted by NumPy ops\n",
    "def sma(y, k):\n",
    "    kernel = np.ones(k) / k\n",
    "    return np.convolve(y, kernel, mode=\"valid\")\n",
    "\n",
    "# Implementation for exponential moving average assisted by NumPy ops\n",
    "def ema(y, alpha=0.2):\n",
    "    out = np.empty_like(y)\n",
    "    out[0] = y[0]\n",
    "    for t in range(1, len(y)):\n",
    "        out[t] = alpha * y[t] + (1 - alpha) * out[t-1]\n",
    "    return out\n",
    "\n",
    "# Handle a NaN in the signal by linear interpolation so filters don't propagate NaNs\n",
    "interp_s = signal_noisy.copy()\n",
    "mask = np.isnan(interp_s)\n",
    "if mask.any():\n",
    "    idx = np.arange(interp_s.size)\n",
    "    interp_s[mask] = np.interp(idx[mask], idx[~mask], interp_s[~mask])\n",
    "   \n",
    "# Generate smoothes arrays \n",
    "sma_s = sma(interp_s, k=5)\n",
    "ema_s = ema(interp_s, alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7a355f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoothed plots in a single plot with matching x/y shapes\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.plot(linspace, interp_s, 'o-', label='Interpolated signal', markersize=5)\n",
    "plt.plot(linspace[2:-2], sma_s, 'o-', label='SMA (k=5)', markersize=5)  # SMA is shorter by k-1\n",
    "plt.plot(linspace, ema_s, 'o-', label='EMA (alpha=0.2)', markersize=5)\n",
    "plt.title('Smoothed Signals')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSE511",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
