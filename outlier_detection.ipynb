{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3305129e",
   "metadata": {},
   "source": [
    "# Outlier Detection: From IQR and Z-scores to K-means distance\n",
    "\n",
    "**Goal:** learn quick, explainable methods to flag outliers, and a clustering-based approach for messy cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639a44c4",
   "metadata": {},
   "source": [
    "## 1. What’s an Outlier?\n",
    "- A data point that is implausible given the bulk of the distribution or business rules.\n",
    "- Treat \"outlier\" as a *hypothesis* to investigate, not a truth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa7836f",
   "metadata": {},
   "source": [
    "## 2. Visual First\n",
    "- Box plots and histograms to see tails\n",
    "- Scatter to check suspicious clusters or isolated points\n",
    "\n",
    "> Exercise: plot hist + box for 2–3 columns, and mark the suspected outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b722a376",
   "metadata": {},
   "source": [
    "## 3. IQR Rule (distribution-agnostic)\n",
    "- Compute Q1, Q3, IQR = Q3 - Q1\n",
    "- Fence: `[Q1 - 1.5*IQR, Q3 + 1.5*IQR]` (tune 1.5 ↔ 3 for stricter/looser)\n",
    "- Flag values outside the fence\n",
    "\n",
    "**Pros:** robust to skew. **Cons:** univariate only unless applied per feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6a8e07",
   "metadata": {},
   "source": [
    "## 4. Z-score (parametric)\n",
    "- `z = (x - mean)/std` and flag `|z| > k` (common k = 3)\n",
    "\n",
    "**Pros:** simple, good when normal-ish. **Cons:** sensitive to outliers affecting mean/std."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ff100a",
   "metadata": {},
   "source": [
    "## 5. Robust Z via Median and MAD\n",
    "- `mad = median(|x - median(x)|)` and `z_robust = 0.6745*(x - median)/mad`\n",
    "- Flag `|z_robust| > k` (k ≈ 3.5 common)\n",
    "\n",
    "**Pros:** resilient to heavy tails. **Cons:** like IQR, typically univariate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d43c2df",
   "metadata": {},
   "source": [
    "## 6. Multivariate Angle: K-means Distance\n",
    "- Fit K-means, compute distance of each point to its assigned centroid\n",
    "- Points with distances in the extreme tail are candidates\n",
    "- Choose K via the elbow method on SSE (sum of squared errors)\n",
    "\n",
    "> Exercise: run K across a range, plot SSE vs K, pick elbow; then flag top 1% farthest points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fdfd5b",
   "metadata": {},
   "source": [
    "## 7. Practical Playbook\n",
    "- Start univariate (IQR/robust-z) to catch obvious issues\n",
    "- Move to multivariate (distance in embedding space, clustering) when needed\n",
    "- Always review a sample of flagged points; never auto-drop without context\n",
    "- After cleaning, re-check distribution and downstream metrics (training stability, convergence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d76a2d",
   "metadata": {},
   "source": [
    "## 8. Reporting\n",
    "- Summarize: how many flagged, by which rule, percent of data removed/edited\n",
    "- Keep a reversible log of changes (row ids, old value → new value, reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04683d41",
   "metadata": {},
   "source": [
    "**Takeaways**\n",
    "- Use simple, explainable rules first.\n",
    "- Robust methods reduce false alarms when data are skewed.\n",
    "- Clustering distances align well with messy, multi-feature data."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
