{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09564573",
   "metadata": {},
   "source": [
    "# Outlier Detection with Cleaned Dataset\n",
    "We’ll use **`cleaned_dataset.csv`**, which has intentional outliers in numeric columns:\n",
    "\n",
    "- `income`: extreme high values planted as outliers with some negatives\n",
    "- `score`: corrupted values (negative or >100)\n",
    "\n",
    "Covered:\n",
    "- **Univariate detection** (IQR, z-scores) on `income` and `score`\n",
    "- **Rule-based detection** (flag impossible values like negative scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beee4cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd45a16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "ROOT_ = os.getcwd()\n",
    "DATA_  = os.path.join(ROOT_, \"data\")\n",
    "\n",
    "# Obtain all CSV file paths in the data directory\n",
    "csv_paths = glob.glob(os.path.join(DATA_, \"*.csv*\"))\n",
    "assert len(csv_paths) > 0, f\"No CSV files found in {DATA_}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a71fd55",
   "metadata": {},
   "source": [
    "## 1. Rule-based Detection (Score sanity checks)\n",
    "Some columns have *hard logical limits* rather than distribution-based limits.\n",
    "\n",
    "**Example:**\n",
    "- `score` should be between 0 and 100 (like a percentage/grade scale)\n",
    "- Any value outside this range is automatically an outlier\n",
    "\n",
    "This shows how domain rules complement statistical detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f34b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned dataset from pandas_basics\n",
    "data_name = \"cleaned\"\n",
    "path = [path for path in csv_paths if data_name in path][0]\n",
    "df_cleaned_dataset = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb72477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule-based detection for `score` and income\n",
    "bad_scores = df_cleaned_dataset[(df_cleaned_dataset['score'] < 0) | (df_cleaned_dataset['score'] > 100)]\n",
    "bad_income = df_cleaned_dataset[df_cleaned_dataset['yearly_income'] < 0]\n",
    "\n",
    "if not bad_income.empty:\n",
    "    print(\"Out-of-range values detected for income:\")\n",
    "    print(bad_income[['yearly_income']].head())\n",
    "\n",
    "if not bad_scores.empty:\n",
    "    print(\"\\nOut-of-range values detected for score:\")\n",
    "    print(bad_scores[['score']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa7836f",
   "metadata": {},
   "source": [
    "## 2. Visual Observations\n",
    "- Box plots and histograms to see tails\n",
    "- Scatter to check suspicious clusters or isolated points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbe0a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print unique values for a specific column and its value counts\n",
    "column = 'score'\n",
    "print(f\"\\nUnique values in 'category' column:\\n{df_cleaned_dataset[column].value_counts(dropna=False)}\")\n",
    "print('-' * 50)\n",
    "\n",
    "# Visualized\n",
    "value_counts = df_cleaned_dataset[column].value_counts(dropna=False)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Histogram with 20 bins\n",
    "ax1.hist(df_cleaned_dataset[column], bins=20, color='skyblue', edgecolor='black', alpha=0.8)\n",
    "ax1.set_xlabel(column.capitalize())\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title(f'Histogram of {column.capitalize()}')\n",
    "\n",
    "# Scatter plot\n",
    "ax2.scatter(df_cleaned_dataset.index, df_cleaned_dataset[column], alpha=0.7, color='skyblue', edgecolor='black')\n",
    "ax2.set_xlabel('Index')\n",
    "ax2.set_ylabel(column.capitalize())\n",
    "ax2.set_title(f'Scatter Plot of {column.capitalize()}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b722a376",
   "metadata": {},
   "source": [
    "## 3. Interquartile Range (IQR) Rule\n",
    "---\n",
    "**Example column:** `income`\n",
    "\n",
    "- Compute Q1, Q3, and IQR = Q3 - Q1\n",
    "- Define fences: `[Q1 - 1.5*IQR, Q3 + 1.5*IQR]`\n",
    "- Flag values outside as potential outliers\n",
    "\n",
    "We’ll apply this to `df['income']` to highlight the planted extreme values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c9e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain column values\n",
    "column = df_cleaned_dataset['yearly_income'].to_numpy()\n",
    "\n",
    "quartiles = np.percentile(column, [25, 75])\n",
    "Q1, Q3 = quartiles\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "print(f\"IQR Method: Lower Bound = {lower_bound}, Upper Bound = {upper_bound}\")\n",
    "print('-' * 50)\n",
    "\n",
    "outliers_iqr = df_cleaned_dataset[(column < lower_bound) | (column > upper_bound)]\n",
    "print(f\"IQR Method: Detected {len(outliers_iqr)} outliers in column.\\n\")\n",
    "print(outliers_iqr.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6a8e07",
   "metadata": {},
   "source": [
    "## 4. Z-score\n",
    "---\n",
    "\n",
    "- Compute z = (x - mean)/std\n",
    "- Flag values with |z| > threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e9e50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain column values\n",
    "column = df_cleaned_dataset['score'].to_numpy()\n",
    "\n",
    "# Calculate Z-Score for each value in column\n",
    "mean = np.mean(column)\n",
    "std_dev = np.std(column)\n",
    "z_scores = (column - mean) / std_dev\n",
    "\n",
    "# If the absolute value of Z-score > threshold, it's an outlier\n",
    "threshold = 1.75\n",
    "outliers_zscore = df_cleaned_dataset[np.abs(z_scores) > threshold]\n",
    "print(f\"\\nZ-Score Method: Detected {len(outliers_zscore)} outliers in column.\")\n",
    "print('-' * 50)\n",
    "print(outliers_zscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ff100a",
   "metadata": {},
   "source": [
    "## 5. Robust Z via Median and MAD\n",
    "- `mad = median(|x - median(x)|)` and `z_robust = 0.6745*(x - median)/mad`\n",
    "- Flag `|z_robust| > k\n",
    "- Better for more skewed data in comparison to normal Z-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bc7696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain column values\n",
    "column = df_cleaned_dataset['score'].to_numpy()\n",
    "\n",
    "# Calculate Z-Score for each value in column\n",
    "median = np.median(column)\n",
    "mad = np.median(np.abs(column - median))\n",
    "z_robust = 0.6745 * (column - median) / mad\n",
    "\n",
    "# If the absolute value of z_robust > threshold, it's an outlier\n",
    "threshold = 1.75\n",
    "outliers_z_robust = df_cleaned_dataset[np.abs(z_scores) > threshold]\n",
    "print(f\"\\nRobust Z-Score Method: Detected {len(outliers_z_robust)} outliers in column.\\n\")\n",
    "print(outliers_z_robust)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSE511",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
